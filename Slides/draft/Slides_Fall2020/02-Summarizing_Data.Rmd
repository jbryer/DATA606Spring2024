---
title: "DATA606 - Summarizing Data"
author: Jason Bryer, Ph.D.
date: "September 2, 2020"
knit: (function(inputFile, encoding) { input.dir <- normalizePath(dirname(inputFile)); rmarkdown::render(input = inputFile, encoding = encoding, quiet=FALSE, output_file = paste0(input.dir,'/../docs/slides/', tools::file_path_sans_ext(basename(inputFile)), '.html')); })
output:
  ioslides_presentation:
    self_contained: true
    widescreen: true
    smaller: true
editor_options: 
  chunk_output_type: console
---

<div class="notes">
Documentation on using ioslides is available here:
http://rmarkdown.rstudio.com/ioslides_presentation_format.html
Some slides are adopted (or copied) from OpenIntro: https://www.openintro.org/
</div>

```{r, echo=FALSE, results='hide'}
library(lego)
data(legosets)
```


## Summarizing Data

We will use the `lego` R package in this class which contains information about every Lego set manufactured from 1970 to 2014, a total of 5710 sets.

```{r, eval=FALSE}
devtools::install_github("seankross/lego")
```
```{r}
library(lego)
data(legosets)
```


## Types of Variables

* Numerical (quantitative)
	* Continuous
	* Discrete
* Categorical (qualitative)
	* Regular categorical
	* Ordinal

## Data Types in R

<center><img src='images/DataTypesConceptModel.png' height='500'></center>


## Types of Variables

```{r}
str(legosets)
```

## Qualitative Variables

Descriptive statistics:

* Contingency Tables
* Proportional Tables

Plot types:

* Bar plot

## Contingency Tables

```{r}
table(legosets$Availability, useNA='ifany')
```

```{r}
table(legosets$Availability, legosets$Packaging, useNA='ifany')
```

## Proportional Tables {.flexbox .vcenter}

```{r}
prop.table(table(legosets$Availability))
```

## Bar Plots {.flexbox .vcenter}

```{r}
barplot(table(legosets$Availability), las=3)
```

## Bar Plots {.flexbox .vcenter}

```{r}
barplot(prop.table(table(legosets$Availability)), las=3)
```


## Quantitative Variables

Descriptive statistics:

* Mean
* Median
* Quartiles
* Variance: ${ s }^{ 2 }=\sum _{ i=1 }^{ n }{ \frac { { \left( { x }_{ i }-\bar { x }  \right)  }^{ 2 } }{ n-1 }  }$
* Standard deviation: $s=\sqrt{s^2}$

Plot types:

* Dot plots
* Histograms
* Density plots
* Box plots
* Scatterplots

## Measures of Center

```{r}
mean(legosets$Pieces, na.rm=TRUE)
median(legosets$Pieces, na.rm=TRUE)
```

## Measures of Spread {.columns-2}

```{r}
var(legosets$Pieces, na.rm=TRUE)
sqrt(var(legosets$Pieces, na.rm=TRUE))
sd(legosets$Pieces, na.rm=TRUE)
```
<br />
```{r}
fivenum(legosets$Pieces, na.rm=TRUE)
IQR(legosets$Pieces, na.rm=TRUE)
```

## The `summary` Function

```{r}
summary(legosets$Pieces)
```

## The `psych` Package

```{r, message=FALSE, warning=FALSE}
library(psych)
describe(legosets$Pieces, skew=FALSE)
describeBy(legosets$Pieces, group = legosets$Availability, skew=FALSE, mat=TRUE)
```

## Robust Statistics

Median and IQR are more robust to skewness and outliers than mean and SD. Therefore,

* for skewed distributions it is often more helpful to use median and IQR to describe the center and spread
* for symmetric distributions it is often more helpful to use the mean and SD to describe the center and spread

## Dot Plot {.flexbox .vcenter}

```{r, fig.height=2.5}
stripchart(legosets$Pieces)
```

## Dot Plot {.flexbox .vcenter}

```{r, fig.height=4}
par.orig <- par(mar=c(1,10,1,1))
stripchart(legosets$Pieces ~ legosets$Availability, las=1)
par(par.orig)
```

## Histograms {.flexbox .vcenter}

```{r}
hist(legosets$Pieces)
```

## Transformations {.flexbox .vcenter}

With highly skewed distributions, it is often helpful to transform the data. The log transformation is a common approach, especially when dealing with salary or similar data.

```{r}
hist(log(legosets$Pieces))
```

## Density Plots {.flexbox .vcenter}

```{r}
plot(density(legosets$Pieces, na.rm=TRUE), main='Lego Pieces per Set')
```

## Density Plot (log tansformed) {.flexbox .vcenter}

```{r}
plot(density(log(legosets$Pieces), na.rm=TRUE), main='Lego Pieces per Set (log transformed)')
```

## Box Plots {.columns-2}

```{r, fig.width=3}
boxplot(legosets$Pieces)
```

```{r, fig.width=3}
boxplot(log(legosets$Pieces))
```

## Scatter Plots {.flexbox .vcenter}

```{r, fig.height=5}
plot(legosets$Pieces, legosets$USD_MSRP)
```

## Examining Possible Outliers (expensive sets)

```{r}
legosets[which(legosets$USD_MSRP >= 400),]
```

## Examining Possible Outliers (big sets)

```{r}
legosets[which(legosets$Pieces >= 4000),]
```

##  {.flexbox .vcenter}

```{r, fig.height=5}
plot(legosets$Pieces, legosets$USD_MSRP)
bigAndExpensive <- legosets[which(legosets$Pieces >= 4000 | legosets$USD_MSRP >= 400),]
text(bigAndExpensive$Pieces, bigAndExpensive$USD_MSRP, labels=bigAndExpensive$Name)
```


## Pie Charts

There is only one pie chart in *OpenIntro Statistics* (Diez, Barr, & Çetinkaya-Rundel, 2015, p. 48). Consider the following three pie charts that represent the preference of five different colors. Is there a difference between the three pie charts? This is probably a difficult to answer.

<center><img src='images/Pie.png' width='500'></center>



## Pie Charts

There is only one pie chart in *OpenIntro Statistics* (Diez, Barr, & Çetinkaya-Rundel, 2015, p. 48). Consider the following three pie charts that represent the preference of five different colors. Is there a difference between the three pie charts? This is probably a difficult to answer.

<center><img src='images/Pie.png' width='500'></center>

<center><img src='images/Bar.png' width='500'></center>

Source: [https://en.wikipedia.org/wiki/Pie_chart](https://en.wikipedia.org/wiki/Pie_chart).

## Just say NO to pie charts! {.flexbox .vcenter}


<blockquote>"There is no data that can be displayed in a pie chart that cannot better be displayed in some other type of chart" <p align='right'>John Tukey</p></blockquote>


## `ggplot2`

* `ggplot2` is an R package that provides an alternative framework based upon Wilkinson’s (2005) Grammar of Graphics.
* `ggplot2` is, in general, more flexible for creating "prettier" and complex plots.
* Works by creating layers of different types of objects/geometries (i.e. bars, points, lines, polygons, etc.)
`ggplot2` has at least three ways of creating plots:
     1. `qplot`
     2. `ggplot(...) + geom_XXX(...) + ...`
     3. `ggplot(...) + layer(...)`
* We will focus only on the second.

## First Example {.flexbox .vcenter}

```{r, message=FALSE,warning=FALSE}
library(ggplot2)
data(diamonds)
ggplot(diamonds, aes(x=carat, y=price, color=cut)) + geom_point()
```

## Parts of a `ggplot2` Statement

* Data  
`ggplot(myDataFrame, aes(x=x, y=y)`
* Layers  
`geom_point()`, `geom_histogram()`
* Facets  
`facet_wrap(~ cut)`, `facet_grid(~ cut)`
* Scales  
`scale_y_log10()`
* Other options  
`ggtitle('my title')`, `ylim(c(0, 10000))`, `xlab('x-axis label')`

## Lots of geoms

```{r}
ls('package:ggplot2')[grep('geom_', ls('package:ggplot2'))]
```

## Scatterplot Revisited {.flexbox .vcenter}

```{r, warning=FALSE}
ggplot(legosets, aes(x=Pieces, y=USD_MSRP)) + geom_point()
```

## Scatterplot Revisited (cont.) {.flexbox .vcenter}

```{r, warning=FALSE}
ggplot(legosets, aes(x=Pieces, y=USD_MSRP, color=Availability)) + geom_point()
```

## Scatterplot Revisited (cont.) {.flexbox .vcenter}

```{r, warning=FALSE}
ggplot(legosets, aes(x=Pieces, y=USD_MSRP, size=Minifigures, color=Availability)) + geom_point()
```

## Scatterplot Revisited (cont.) {.flexbox .vcenter}

```{r, warning=FALSE}
ggplot(legosets, aes(x=Pieces, y=USD_MSRP, size=Minifigures)) + geom_point() + facet_wrap(~ Availability)
```

## Boxplots Revisited {.flexbox .vcenter}

```{r, warning=FALSE}
ggplot(legosets, aes(x='Lego', y=USD_MSRP)) + geom_boxplot()
```

## Boxplots Revisited (cont.) {.flexbox .vcenter}

```{r, warning=FALSE}
ggplot(legosets, aes(x=Availability, y=USD_MSRP)) + geom_boxplot()
```

## Boxplots Revisited (cont.) {.flexbox .vcenter}

```{r, warning=FALSE}
ggplot(legosets, aes(x=Availability, y=USD_MSRP)) + geom_boxplot() + coord_flip()
```

## Likert Scales

Likert scales are a type of questionaire where respondents are asked to rate items on scales usually ranging from four to seven levels (e.g. strongly disagree to strongly agree).

```{r, message=FALSE, warning=FALSE}
library(likert)
library(reshape)
data(pisaitems)
items24 <- pisaitems[,substr(names(pisaitems), 1,5) == 'ST24Q']
items24 <- rename(items24, c(
			ST24Q01="I read only if I have to.",
			ST24Q02="Reading is one of my favorite hobbies.",
			ST24Q03="I like talking about books with other people.",
			ST24Q04="I find it hard to finish books.",
			ST24Q05="I feel happy if I receive a book as a present.",
			ST24Q06="For me, reading is a waste of time.",
			ST24Q07="I enjoy going to a bookstore or a library.",
			ST24Q08="I read only to get information that I need.",
			ST24Q09="I cannot sit still and read for more than a few minutes.",
			ST24Q10="I like to express my opinions about books I have read.",
			ST24Q11="I like to exchange books with my friends."))

```

## `likert` R Package

```{r}
l24 <- likert(items24)
summary(l24)
```

## `likert` Plots {.flexbox .vcenter}

```{r, fig.width=8}
plot(l24)
```

## `likert` Plots {.flexbox .vcenter}

```{r, fig.width=8}
plot(l24, type='heat')
```

## `likert` Plots {.flexbox .vcenter}

```{r, fig.width=4, fig.height=7}
plot(l24, type='density')
```


## Dual Scales

Some problems<sup>1</sup>:

* The designer has to make choices about scales and this can have a big impact on the viewer
* "Cross-over points” where one series cross another are results of the design choices, not intrinsic to the data, and viewers (particularly unsophisticated viewers)
* They make it easier to lazily associate correlation with causation, not taking into account autocorrelation and other time-series issues
* Because of the issues above, in malicious hands they make it possible to deliberately mislead

This example looks at the relationship between NZ dollar exchange rate and trade weighted index.

```{r, eval=FALSE}
library(DATA606)
shiny_demo('DualScales', package='DATA606')
```

My advise:

* Avoid using them. You can usually do better with other plot types.
* When necessary (or compelled) to use them, rescale (using z-scores)

<sup>1</sup> http://blog.revolutionanalytics.com/2016/08/dual-axis-time-series.html
<sup>2</sup> http://ellisp.github.io/blog/2016/08/18/dualaxes
